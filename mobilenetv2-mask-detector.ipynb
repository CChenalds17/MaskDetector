{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import keras.layers\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from imutils import paths\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "dropout = 0.2\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskoff_paths = list(paths.list_images('faces/maskoff/'))\n",
    "maskon_paths = list(paths.list_images('faces/maskon/'))\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# maskoff\n",
    "for maskoff_path in maskoff_paths:\n",
    "    label = 'maskoff'\n",
    "    image = load_img(maskoff_path, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "# maskon\n",
    "for maskon_path in maskon_paths:\n",
    "    label = 'maskon'\n",
    "    image = load_img(maskon_path, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, test_x, train_y, test_y) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=image_size + (3,))\n",
    "head_model = base_model.output\n",
    "head_model = keras.layers.AveragePooling2D(pool_size=(7, 7))(head_model)\n",
    "head_model = keras.layers.Flatten(name=\"flatten\")(head_model)\n",
    "head_model = keras.layers.Dense(128, activation=\"relu\")(head_model)\n",
    "head_model = keras.layers.Dropout(0.5)(head_model)\n",
    "head_model = keras.layers.Dense(2, activation=\"softmax\")(head_model)\n",
    "\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=head_model)\n",
    "for layer in base_model.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "train_generator = aug.flow(\n",
    "    train_x, train_y,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"saved_models/RGB_3/save_at_{epoch}.keras\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=lr, decay = lr / epochs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 [==============================] - 37s 697ms/step - loss: 0.7574 - accuracy: 0.5989 - val_loss: 0.5559 - val_accuracy: 0.7910\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 29s 621ms/step - loss: 0.5785 - accuracy: 0.7283 - val_loss: 0.4493 - val_accuracy: 0.8598\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 30s 629ms/step - loss: 0.5014 - accuracy: 0.7886 - val_loss: 0.3831 - val_accuracy: 0.8995\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 30s 632ms/step - loss: 0.4266 - accuracy: 0.8347 - val_loss: 0.3463 - val_accuracy: 0.9101\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 31s 648ms/step - loss: 0.4161 - accuracy: 0.8320 - val_loss: 0.3254 - val_accuracy: 0.8968\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 31s 653ms/step - loss: 0.3797 - accuracy: 0.8509 - val_loss: 0.2919 - val_accuracy: 0.9180\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 34s 718ms/step - loss: 0.3539 - accuracy: 0.8598 - val_loss: 0.2801 - val_accuracy: 0.9180\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 34s 711ms/step - loss: 0.3356 - accuracy: 0.8686 - val_loss: 0.2646 - val_accuracy: 0.9233\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 30s 636ms/step - loss: 0.3243 - accuracy: 0.8699 - val_loss: 0.2533 - val_accuracy: 0.9180\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 31s 648ms/step - loss: 0.2921 - accuracy: 0.8923 - val_loss: 0.2359 - val_accuracy: 0.9259\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 29s 611ms/step - loss: 0.3159 - accuracy: 0.8720 - val_loss: 0.2250 - val_accuracy: 0.9339\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 29s 611ms/step - loss: 0.2930 - accuracy: 0.8841 - val_loss: 0.2248 - val_accuracy: 0.9339\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 28s 602ms/step - loss: 0.2664 - accuracy: 0.9024 - val_loss: 0.2092 - val_accuracy: 0.9365\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 29s 610ms/step - loss: 0.2542 - accuracy: 0.9085 - val_loss: 0.2109 - val_accuracy: 0.9339\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 29s 606ms/step - loss: 0.2632 - accuracy: 0.9085 - val_loss: 0.2045 - val_accuracy: 0.9365\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - 29s 629ms/step - loss: 0.2459 - accuracy: 0.9051 - val_loss: 0.1950 - val_accuracy: 0.9392\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - 29s 612ms/step - loss: 0.2365 - accuracy: 0.9092 - val_loss: 0.1885 - val_accuracy: 0.9418\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - 29s 610ms/step - loss: 0.2389 - accuracy: 0.9106 - val_loss: 0.1896 - val_accuracy: 0.9365\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - 29s 605ms/step - loss: 0.2310 - accuracy: 0.9160 - val_loss: 0.1776 - val_accuracy: 0.9392\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - 29s 609ms/step - loss: 0.2252 - accuracy: 0.9146 - val_loss: 0.1741 - val_accuracy: 0.9418\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_x) // batch_size,\n",
    "\tvalidation_data=(test_x, test_y),\n",
    "\tvalidation_steps=len(test_x) // batch_size,\n",
    "\tepochs=epochs,\n",
    "    callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
